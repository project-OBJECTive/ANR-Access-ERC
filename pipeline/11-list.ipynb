{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the list of objects from the transcription, in order to have one line for each lots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "import re\n",
    "import lib\n",
    "from openai import OpenAI\n",
    "from mistralai import Mistral\n",
    "import ollama\n",
    "import yaml\n",
    "\n",
    "# Paremeters from config file\n",
    "with open(\"./00-config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "catalog = config['catalog']['folder_name']\n",
    "page_begin = config['catalog']['object_list_begin_page']\n",
    "page_end = config['catalog']['object_list_end_page']\n",
    "mode = config['model']['mode']\n",
    "llm_provider = config['model']['llm_provider']\n",
    "model = config['model']['language_model']\n",
    "pages_parsed_at_once = config['model']['pages_parsed_at_once']\n",
    "if not page_end: page_end = float('inf')\n",
    "\n",
    "# Overwrite variables in case of pipeline mode\n",
    "if os.getenv('OBJECTIVE_MODE') == 'pipeline':\n",
    "    catalog = os.getenv('OBJECTIVE_CATALOG')\n",
    "    page_begin_given = os.getenv('OBJECTIVE_PAGE_BEGIN')\n",
    "    page_end_given = os.getenv('OBJECTIVE_PAGE_END')\n",
    "    page_begin = int(page_begin_given) if page_begin_given != '' else page_begin\n",
    "    page_end = int(page_end_given) if page_end_given != '' else page_end\n",
    "\n",
    "# Global variables\n",
    "folder_path = f\"../catalogs/{catalog}\"\n",
    "eta = lib.Eta()\n",
    "if llm_provider == \"mistralai\": client = Mistral(api_key=os.getenv(\"MISTRALAI_API_KEY_OBJECTIVE\"))\n",
    "if llm_provider == \"openai\": client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY_OBJECTIVE\"))\n",
    "input_path = f'{folder_path}/transcription.txt'\n",
    "output_path = f'{folder_path}/list.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts that will be sent to the LLM\n",
    "prompt = f\"\"\"\n",
    "From the following extract of an old auction catalog, list me all objects (original number + all description in original language + any other information about the object like details, dimensions, story, ...) that are being sold.\n",
    "I would like your answer to be a list: do not make aditional comment, note or explaination.\n",
    "The format of a single description should be for example: \"18 - Lorem Ipsum...\" with everything in a single line.\n",
    "Ignore footnotes.\n",
    "\n",
    "Here is the extract: \n",
    "\"//extract//\" \n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transcription\n",
    "file = open(input_path, 'r')\n",
    "transcription = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and clean pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = []\n",
    "\n",
    "# Remove page separators and empty pages.\n",
    "pattern = r\">>>>> \\[PAGE \\d+\\] >>>>>\\n\\n\"\n",
    "for match in re.finditer(pattern, transcription):\n",
    "\n",
    "    # Extract the page content without its title\n",
    "    page_begin_idx = match.end()\n",
    "    rest_transcription = transcription[match.end():]\n",
    "    next_match = re.search(pattern, rest_transcription)\n",
    "    if next_match:\n",
    "        page_end_idx = re.search(pattern, rest_transcription).start()\n",
    "        page_content = rest_transcription[0:page_end_idx].strip()\n",
    "    else:\n",
    "        page_content = rest_transcription\n",
    "\n",
    "    # Exclude empty pages\n",
    "    page_content = page_content.replace('[No text]', '')\n",
    "\n",
    "    # Record the page if there is something\n",
    "    pages.append(page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List objects (with LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'direct':\n",
    "\n",
    "    # Retrieve informations\n",
    "    all_objects = []\n",
    "\n",
    "    eta.begin(len(pages), \"Retrieving object list\")\n",
    "    for extrac_begin_page in range(page_begin, min(page_end, len(pages)), pages_parsed_at_once):\n",
    "        extract_end_page = extrac_begin_page + pages_parsed_at_once\n",
    "\n",
    "        # Build the prompt\n",
    "        # Here we start one page before, \n",
    "        # in order to have the object description that has been cut by the new page\n",
    "        extract = '\\n\\n'.join(pages[extrac_begin_page - 1:extract_end_page])\n",
    "        prompt_ = prompt.replace('//extract//', extract)\n",
    "\n",
    "        messages = [{'role': 'user', 'content': prompt_}]\n",
    "\n",
    "        # Ask the LLM\n",
    "        if llm_provider == 'openai':\n",
    "            response = client.chat.completions.create(model=model, messages=messages)\n",
    "            answer = response.choices[0].message.content\n",
    "        if llm_provider == 'ollama':\n",
    "            response = ollama.chat(model=model, messages=messages)  \n",
    "            answer = response['message']['content']\n",
    "        if llm_provider == 'mistralai':\n",
    "            response = client.chat.complete(model=model, messages=messages)\n",
    "            answer = response.choices[0].message.content\n",
    "\n",
    "        # Save the raw list object\n",
    "        file = open(output_path, 'a')\n",
    "        file.write('\\n' + answer.replace('—', '-'))\n",
    "        file.close()\n",
    "\n",
    "        eta.iter(extrac_begin_page)\n",
    "    eta.end()\n",
    "\n",
    "    # Now that everything is done, load all objects\n",
    "    file = open(output_path, 'r')\n",
    "    objects = file.read().split('\\n')\n",
    "    file.close()\n",
    "\n",
    "    # Deduplicate objects\n",
    "    objects = list(set(objects))\n",
    "\n",
    "    # Write objects list on disk\n",
    "    print('### Save object list')\n",
    "    file = open(output_path, 'w')\n",
    "    file.write(objects.join('\\n'))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH: Prepare tasks\n",
    "\n",
    "if mode == 'batch':\n",
    "\n",
    "    batch_tasks = []\n",
    "\n",
    "    eta.begin(len(pages), \"Retrieving object list\")\n",
    "    for extrac_begin_page in range(page_begin, min(page_end, len(pages)), pages_parsed_at_once):\n",
    "        extract_end_page = extrac_begin_page + pages_parsed_at_once\n",
    "\n",
    "        # Build the prompt\n",
    "        # Here we start one page before, \n",
    "        # in order to have the object description that has been cut by the new page\n",
    "        extract = '\\n\\n'.join(pages[extrac_begin_page - 1:extract_end_page])\n",
    "        prompt_ = prompt.replace('//extract//', extract)\n",
    "        messages = [{'role': 'user', 'content': prompt_}]\n",
    "        custom_id = f\"{catalog}-object-list-{str(extrac_begin_page).zfill(4)}\"\n",
    "\n",
    "        # Create an OpenAI task\n",
    "        if llm_provider == 'openai':\n",
    "            batch_tasks.append({\n",
    "                \"custom_id\": custom_id, \n",
    "                \"method\": \"POST\", \n",
    "                \"url\": \"/v1/chat/completions\", \n",
    "                \"body\": {\"model\": model, \"messages\": messages }\n",
    "            })\n",
    "            \n",
    "        # Create a MistralAI task\n",
    "        if llm_provider == 'mistralai':\n",
    "            batch_tasks.append({ \n",
    "                \"custom_id\": custom_id, \n",
    "                \"body\": { \"messages\": messages }\n",
    "            })\n",
    "\n",
    "        # Create an Ollama task\n",
    "        if llm_provider == \"ollama\": \n",
    "            raise Exception('Batch not implemented with Ollama')\n",
    "\n",
    "        eta.iter(extrac_begin_page)\n",
    "    eta.end()\n",
    "\n",
    "    print(f'{len(batch_tasks)} tasks created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH: Create the batch (and wait for results)\n",
    "\n",
    "if mode == \"batch\":\n",
    "    if llm_provider == \"mistralai\":\n",
    "        answers = lib.mistralai_batch_execution(\n",
    "            tasks=batch_tasks,\n",
    "            client=client, model=model, file_name=catalog, task_name=f\"{catalog}_list\"\n",
    "        )\n",
    "    if llm_provider == \"openai\":\n",
    "        answers = lib.openai_batch_execution(\n",
    "            task=batch_tasks, endpoint=\"/v1/chat/completions\",\n",
    "            client=client, mistral_file_name=catalog, task_name=f\"{catalog}_list\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH: Parse object list and save them\n",
    "\n",
    "if mode == 'batch':\n",
    "\n",
    "    # Extract the full object list\n",
    "    objects = []\n",
    "    for answer in answers:\n",
    "        objects += answer.replace('—', '-').split('\\n')\n",
    "\n",
    "    # Remove prepending quotes\n",
    "    for i, _ in enumerate(objects):\n",
    "        if objects[i].startswith('\"') or objects[i].startswith(\"'\"):\n",
    "            objects[i] = objects[i][1:]\n",
    "        if objects[i].endswith('\"') or objects[i].endswith(\"'\"):\n",
    "            objects[i] = objects[i][:-1]\n",
    "\n",
    "    # Deduplicate objects\n",
    "    clean_object = []\n",
    "    have_objects = set()\n",
    "    for object in objects:\n",
    "        if object == '': \n",
    "            continue\n",
    "        elif object not in have_objects:\n",
    "            clean_object.append(object)\n",
    "            have_objects.add(object)\n",
    "\n",
    "    \n",
    "    # Save the object list\n",
    "    print('### Save object list')\n",
    "    file = open(output_path, 'w')\n",
    "    file.write('\\n'.join(clean_object))\n",
    "    file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
