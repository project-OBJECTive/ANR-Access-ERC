{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply various rules of corrections to objects information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, datetime\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "import pandas as pd\n",
    "import lib\n",
    "import yaml\n",
    "\n",
    "# Global variables\n",
    "eta = lib.Eta()\n",
    "input_path = \"../data/objects-all.csv\"\n",
    "output_path = \"../data/objects-all.csv\"\n",
    "corrections_path = f\"./02-corrections.yaml\"\n",
    "authors_blacklist_path = f\"./01-authors-blacklist.yaml\"\n",
    "corrections = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = pd.read_csv(input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(corrections_path, \"r\") as f:\n",
    "    corrections = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove prepending articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ETA] Remove prepending articles - 3544 iterations in 00h00m00s (avg of 00h00m00s/iter)               \n"
     ]
    }
   ],
   "source": [
    "prepending_articles = [\"un\", \"une\"]\n",
    "\n",
    "eta.begin(len(objects), \"Remove prepending articles\")\n",
    "for i, row in objects.iterrows():\n",
    "\n",
    "    # object_type\n",
    "    if pd.notna(row['object_type']):\n",
    "        object_types = row['object_type'].split(', ')\n",
    "        new_obj_types = []\n",
    "        for object_type in object_types:\n",
    "            words = object_type.split(' ')\n",
    "            new_words = []\n",
    "            for word in words:\n",
    "                if word not in prepending_articles: \n",
    "                    new_words.append(word)\n",
    "            new_obj_types.append(' '.join(new_words))\n",
    "        objects.at[i, 'object_type'] = ', '.join(new_obj_types)\n",
    "\n",
    "    # material_technique\n",
    "    if pd.notna(row['material_technique']):\n",
    "        mat_techs = row['material_technique'].split(', ')\n",
    "        new_mat_techs = []\n",
    "        for mat_tech in mat_techs:\n",
    "            words = mat_tech.split(' ')\n",
    "            new_words = []\n",
    "            for word in words:\n",
    "                if word not in prepending_articles: \n",
    "                    new_words.append(word)\n",
    "            new_mat_techs.append(' '.join(new_words))\n",
    "        objects.at[i, 'material_technique'] = ', '.join(new_mat_techs)\n",
    "\n",
    "    # origins\n",
    "    if pd.notna(row['origin']):\n",
    "        origins = row['origin'].split(', ')\n",
    "        new_origins = []\n",
    "        for origin in origins:\n",
    "            words = origin.split(' ')\n",
    "            new_words = []\n",
    "            for word in words:\n",
    "                if word not in prepending_articles: \n",
    "                    new_words.append(word)\n",
    "            new_origins.append(' '.join(new_words))\n",
    "        objects.at[i, 'origin'] = ', '.join(new_origins)\n",
    "\n",
    "    eta.iter()\n",
    "eta.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply some various rules (NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ETA] Applying various NLP rules - 3544 iterations in 00h00m00s (avg of 00h00m00s/iter)               \n"
     ]
    }
   ],
   "source": [
    "eta.begin(len(objects), \"Applying various NLP rules\")\n",
    "for i, _ in objects.iterrows():\n",
    "\n",
    "    # Remove spaces after quotes\n",
    "    if pd.notna(objects.at[i, 'description']):\n",
    "        objects.at[i, 'description'] = objects.at[i, 'description'].replace(\"' \", \"'\").replace(\"’ \", \"'\")\n",
    "    if pd.notna(objects.at[i, 'object_type']):\n",
    "        objects.at[i, 'object_type'] = objects.at[i, 'object_type'].replace(\"' \", \"'\").replace(\"’ \", \"'\")\n",
    "    if pd.notna(objects.at[i, 'material_technique']):\n",
    "        objects.at[i, 'material_technique'] = objects.at[i, 'material_technique'].replace(\"' \", \"'\").replace(\"’ \", \"'\")\n",
    "\n",
    "    # Remove the unrelevant spaces around dashes\n",
    "    if pd.notna(objects.at[i, 'object_type']):\n",
    "        objects.at[i, 'object_type'] = objects.at[i, 'object_type'].replace(\" - \", \"-\")\n",
    "    if pd.notna(objects.at[i, 'material_technique']):\n",
    "        objects.at[i, 'material_technique'] = objects.at[i, 'material_technique'].replace(\" - \", \"-\")\n",
    "\n",
    "    eta.iter()\n",
    "eta.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply corrections (from correction file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ETA] Apply corrections from correction file - 3544 iterations in 00h00m00s (avg of 00h00m00s/iter)               \n"
     ]
    }
   ],
   "source": [
    "def clean_str(text: str) -> str:\n",
    "    text = text.strip()\n",
    "    if text.endswith('-'): \n",
    "        text = text[-1:]\n",
    "    text = text.replace('’ ', \"' \")\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "eta.begin(len(objects), 'Apply corrections from correction file')\n",
    "for i, row in objects.iterrows():\n",
    "\n",
    "    # object_type\n",
    "    if pd.notna(row['object_type']):\n",
    "\n",
    "        # Get all object_types\n",
    "        object_types = row['object_type'].split(', ')\n",
    "        object_types_corrected = []\n",
    "\n",
    "        # For each one of them, check if there is a correction, if yes, replace it, otherwise keep it as is\n",
    "        for object_type in object_types:\n",
    "            object_type = object_type.lower()\n",
    "\n",
    "            # From the \"all\" section:\n",
    "            if object_type in corrections['all']:\n",
    "                object_types_corrected.append(corrections['all'][object_type])\n",
    "\n",
    "            # From the \"object_type\" section:\n",
    "            elif object_type in corrections['object_type']:\n",
    "                object_types_corrected.append(corrections['object_type'][object_type])\n",
    "\n",
    "            # Otherwise, leave it untouched\n",
    "            else:\n",
    "                object_types_corrected.append(object_type)\n",
    "\n",
    "        # Apply changes\n",
    "        objects.at[i, 'object_type'] = ', '.join(list(map(lambda txt: clean_str(txt), object_types_corrected)))\n",
    "\n",
    "\n",
    "    # material_technique\n",
    "    if pd.notna(row['material_technique']):\n",
    "\n",
    "        # Get all material_technique\n",
    "        materials = row['material_technique'].split(', ')\n",
    "        materials_corrected = []\n",
    "\n",
    "        # For each one of them, check if there is a correction, if yes, replace it, otherwise keep it as is\n",
    "        for material in materials:\n",
    "            material = material.lower()\n",
    "\n",
    "            # From the \"all\" section:\n",
    "            if material in corrections['all']:\n",
    "                materials_corrected.append(corrections['all'][material])\n",
    "\n",
    "            # From the \"material_technique\" section:\n",
    "            elif material in corrections['material_technique']:\n",
    "                materials_corrected.append(corrections['material_technique'][material])\n",
    "\n",
    "            # Otherwise, leave it untouched\n",
    "            else:\n",
    "                materials_corrected.append(material)\n",
    "\n",
    "        # Apply changes\n",
    "        objects.at[i, 'material_technique'] = ', '.join(list(map(lambda txt: clean_str(txt), materials_corrected)))\n",
    "\n",
    "\n",
    "    # origin\n",
    "    if pd.notna(row['origin']):\n",
    "\n",
    "        # Get all origin\n",
    "        origins = row['origin'].split(', ')\n",
    "        origins_corrected = []\n",
    "\n",
    "        # For each one of them, check if there is a correction, if yes, replace it, otherwise keep it as is\n",
    "        for origin in origins:\n",
    "            origin = origin.lower()\n",
    "\n",
    "            # From the \"all\" section:\n",
    "            if origin in corrections['all']:\n",
    "                origins_corrected.append(corrections['all'][origin])\n",
    "\n",
    "            # From the \"origin\" section:\n",
    "            elif origin in corrections['origin']:\n",
    "                origins_corrected.append(corrections['origin'][origin])\n",
    "\n",
    "            # Otherwise, leave it untouched\n",
    "            else:\n",
    "                origins_corrected.append(origin)\n",
    "\n",
    "        # Apply changes\n",
    "        objects.at[i, 'origin'] = ', '.join(list(map(lambda txt: clean_str(txt), origins_corrected)))\n",
    "\n",
    "    # period\n",
    "    if pd.notna(row['period']):\n",
    "\n",
    "        # Get all period\n",
    "        periods = row['period'].split(', ')\n",
    "        periods_corrected = []\n",
    "\n",
    "        # For each one of them, check if there is a correction, if yes, replace it, otherwise keep it as is\n",
    "        for period in periods:\n",
    "            period = period.lower()\n",
    "\n",
    "            # From the \"all\" section:\n",
    "            if period in corrections['all']:\n",
    "                periods_corrected.append(corrections['all'][period])\n",
    "\n",
    "            # From the \"period\" section:\n",
    "            elif period in corrections['period']:\n",
    "                periods_corrected.append(corrections['period'][period])\n",
    "\n",
    "            # Otherwise, leave it untouched\n",
    "            else:\n",
    "                periods_corrected.append(period)\n",
    "\n",
    "        # Apply changes\n",
    "        objects.at[i, 'period'] = ', '.join(list(map(lambda txt: clean_str(txt), periods_corrected)))\n",
    "\n",
    "    # author\n",
    "    if pd.notna(row['author']):\n",
    "\n",
    "        # Get all author\n",
    "        authors = row['author'].split(', ')\n",
    "        authors_corrected = []\n",
    "\n",
    "        # For each one of them, check if there is a correction, if yes, replace it, otherwise keep it as is\n",
    "        for author in authors:\n",
    "            author = author.lower()\n",
    "\n",
    "            # From the \"all\" section:\n",
    "            if author in corrections['all']:\n",
    "                authors_corrected.append(corrections['all'][author])\n",
    "\n",
    "            # From the \"author\" section:\n",
    "            elif author in corrections['author']:\n",
    "                authors_corrected.append(corrections['author'][author])\n",
    "\n",
    "            # Otherwise, leave it untouched\n",
    "            else:\n",
    "                authors_corrected.append(author)\n",
    "\n",
    "        # Apply changes\n",
    "        objects.at[i, 'author'] = ', '.join(list(map(lambda txt: clean_str(txt), authors_corrected)))\n",
    "\n",
    "    eta.iter()\n",
    "eta.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply other manual corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, _ in objects.iterrows():\n",
    "\n",
    "    # Prepare variables\n",
    "    descr = objects.at[i, 'description'].lower() if pd.notna(objects.at[i, 'description']) else \"\"\n",
    "    obj_type = objects.at[i, 'object_type'].lower() if pd.notna(objects.at[i, 'object_type']) else \"\"\n",
    "    mat_tech = objects.at[i, 'material_technique'].lower() if pd.notna(objects.at[i, 'material_technique']) else \"\"\n",
    "    origin = objects.at[i, 'origin'].lower() if pd.notna(objects.at[i, 'origin']) else \"\"\n",
    "    period = objects.at[i, 'period'].lower() if pd.notna(objects.at[i, 'period']) else \"\"\n",
    "    author = objects.at[i, 'author'].lower() if pd.notna(objects.at[i, 'author']) else \"\"\n",
    "\n",
    "\n",
    "    ##### PORCELAINES #####\n",
    "\n",
    "    # Whenever there is \"porcelaine de nymphenburg\" in the description, the origin is \"Nymphenburg\"\n",
    "    if \"porcelaine de nymphenburg\" in descr:\n",
    "        author = lib.add_element(author, \"Nymphenburg\")\n",
    "        origin = lib.add_element(origin, \"Nymphenburg\")\n",
    "\n",
    "\n",
    "    ##### BRONZES #####\n",
    "\n",
    "    # All \"bronze florentin\" are actually \"bronze\" and origin is \"Florence\"\n",
    "    if \"bronze florentin\" in mat_tech:\n",
    "        mat_tech = lib.remove_element(mat_tech, 'bronze florentin')\n",
    "        mat_tech = lib.add_element(mat_tech, 'bronze')\n",
    "        origin = lib.add_element(origin, 'Florence')\n",
    "\n",
    "\n",
    "    ##### KINGS #####\n",
    "\n",
    "    if lib.has_element(period, 'henri ii'):\n",
    "        period = lib.remove_element(period, 'henri ii')\n",
    "        origin = lib.add_element(origin, 'France')\n",
    "        period = lib.add_element(period, 'xvie siècle')\n",
    "        \n",
    "    if lib.has_element(period, 'henri iv'):\n",
    "        period = lib.remove_element(period, 'henri iv')\n",
    "        origin = lib.add_element(origin, 'France')\n",
    "        period = lib.add_element(period, 'xvie siècle')\n",
    "\n",
    "    if lib.has_element(period, 'louis xiii'):\n",
    "        origin = lib.add_element(origin, 'France')\n",
    "\n",
    "    if lib.has_element(period, 'louis xiv'):\n",
    "        origin = lib.add_element(origin, 'France')\n",
    "\n",
    "    if lib.has_element(period, 'louis xv'):\n",
    "        origin = lib.add_element(origin, 'France')\n",
    "    \n",
    "    if lib.has_element(period, 'louis xvi'):\n",
    "        origin = lib.add_element(origin, 'France')\n",
    "    \n",
    "    if lib.has_element(period, 'napoleon'):\n",
    "        origin = lib.add_element(origin, 'France')\n",
    "        period = lib.add_element(period, 'Empire')\n",
    "\n",
    "    if lib.has_element(period, 'françois 1er'):\n",
    "        origin = lib.add_element(origin, 'France')\n",
    "        period = lib.add_element(period, 'xvie siècle')\n",
    "    \n",
    "\n",
    "    ##### STYLES #####\n",
    "\n",
    "    if 'rocaille' in descr:\n",
    "        origin = lib.add_element(origin, 'France')\n",
    "        period = lib.add_element(period, 'Louis XV')\n",
    "    if lib.has_element(period, 'rocaille'):\n",
    "        period = lib.remove_element(period, 'rocaille')\n",
    "        period = lib.add_element(period, 'Louis XV')\n",
    "    if 'régence' in descr:\n",
    "        origin = lib.add_element(origin, 'France')\n",
    "        period = lib.add_element(period, 'Régence')\n",
    "    if 'empire' in descr:\n",
    "        origin = lib.add_element(origin, 'France')\n",
    "        period = lib.add_element(period, 'Empire')\n",
    "    if 'restauration' in descr:\n",
    "        origin = lib.add_element(origin, 'France')\n",
    "    if 'renaissance' in descr:\n",
    "        origin = lib.add_element(origin, 'Europe')\n",
    "        period = lib.add_element(period, 'XVI')\n",
    "    if 'rococo' in descr:\n",
    "        origin = lib.add_element(origin, 'Italie')\n",
    "\n",
    "\n",
    "    ##### MISC #####\n",
    "\n",
    "    # All \"pierre de lard\" are from \"chine\"\n",
    "    if \"pierre de lard\" in mat_tech or \"pierre de lard\" in descr:\n",
    "        origin = lib.add_element(origin, 'Chine')\n",
    "\n",
    "    # Replace \"tasse\" by \"coupe\" when it is a mistake\n",
    "    if \"tasse\" in obj_type and \"tasse\" not in descr and \"coupe\" in descr:\n",
    "        obj_type = lib.remove_element(obj_type, \"tasse\")\n",
    "        obj_type = lib.add_element(obj_type, \"coupe\")\n",
    "\n",
    "    # All \"jade\" are from \"chine\"\n",
    "    if \"jade\" in mat_tech:\n",
    "        origin = lib.add_element(origin, 'Chine')\n",
    "\n",
    "    # If there is only \"émail\" as an object type, it is actually a \"plaque en émail\"\n",
    "    obj_types = obj_type.split(', ')\n",
    "    for obj in obj_types:\n",
    "        if obj == \"émail\":\n",
    "            obj_type = lib.remove_element(obj_type, \"émail\")\n",
    "            obj_type = lib.add_element(obj_type, \"plaque en émail\")\n",
    "            break\n",
    "\n",
    "    # Whenever there is \"tonkin\" in the description, it comes from Vietnam\n",
    "    if \"tonkin\" in descr:\n",
    "        origin = lib.add_element(origin, \"Vietnam\")\n",
    "\n",
    "    # Remove \"Tonkin\" from origins\n",
    "    if \"tonkin\" in origin:\n",
    "        origin = lib.remove_element(origin, 'tonkin')\n",
    "\n",
    "    # Whenever there is \"bocaro\" or \"boccaro\" in the description, it comes from italie\n",
    "    if \"bocaro\" in descr or \"boccaro\" in descr:\n",
    "        origin = lib.add_element(origin, \"italie\")\n",
    "\n",
    "    # Remove \"bocaro\" from origins\n",
    "    if \"bocaro\" in origin:\n",
    "        origin = lib.remove_element(origin, 'bocaro')\n",
    "    # Remove \"boccaro\" from origins\n",
    "    if \"boccaro\" in origin:\n",
    "        origin = lib.remove_element(origin, 'boccaro')\n",
    "\n",
    "    # If \"sèvres\" in origin, it is also an author\n",
    "    if \"sèvres\" in origin:\n",
    "        author = lib.add_element(author, 'sèvres')\n",
    "\n",
    "    # If \"gobelins\" in origin, it is also an author\n",
    "    if \"gobelins\" in origin:\n",
    "        author = lib.add_element(author, 'gobelins')\n",
    "\n",
    "    # Remove elements from object types (errors)\n",
    "    remove_object_types = [\n",
    "        \"groupe\", \"tête\", \"objet\", \"idem\", \"chien\", \"chat\", \"cheval\", \"éléphant\", \"autre\", \"poule\",\n",
    "        \"baroques\", \"la vierge et l'enfant jésus\", \"dame\", \"aigle\", \"chien de fó\", \"femme\", \"mort de cléopâtre\"\n",
    "        \"saint jean\", \"sphinx\", \"groupe d'enfant\", \"chien de fô\", \"tête d'enfant\", \"mandarin\", \"jeune femme\",\n",
    "        \"mars et vénus\", \"pièce diverses\", \"tête d'homme\", \"tête de femme\"\n",
    "    ]\n",
    "    for elt in remove_object_types:\n",
    "        if lib.has_element(obj_type, elt):\n",
    "            obj_type = lib.remove_element(obj_type, elt)\n",
    "\n",
    "\n",
    "    # Origins\n",
    "    # All of following origins are not origins, but actually a period\n",
    "    replace_origins_by_periods = [\n",
    "        \"régence\", \"rocaille\", \"bas-empire\", \"gothique\", \"empire\", \n",
    "        \"renaissance\", \"antique\", \"époque régence\", \"roman\"\n",
    "    ]\n",
    "    for elt in replace_origins_by_periods:\n",
    "        if lib.has_element(origin, elt):\n",
    "            origin = lib.remove_element(origin, elt)\n",
    "            period = lib.add_element(period, elt)\n",
    "    \n",
    "\n",
    "    # Origins\n",
    "    # All of following origins are not origins, but actually authors\n",
    "    replace_origins_by_author = [\n",
    "        \"thomire\", \"palissy\", \"boule\", \"donatello\", \"de lafosse\", \n",
    "        \"wedgwood\", \"atelier d' erhard\", \"savonnerie\"\n",
    "    ]\n",
    "    for elt in replace_origins_by_author:\n",
    "        if lib.has_element(origin, elt):\n",
    "            origin = lib.remove_element(origin, elt)\n",
    "            author = lib.add_element(author, elt)\n",
    "    \n",
    "    # Origin blacklist\n",
    "    origin_blacklist = [\n",
    "        \"palais de versailles\", \"grand-trianon\", \"mauresque\", \"clèves\", \"caroline\", \"la bastille\", \"christ en bas-rhin\", \n",
    "        \"ce des inde\", \"tour\", \"nord\", \"trianon\", \"tartare\", \"malmaison\", \"maremme\", \"moine\", \"mauresque\", \"juliers\", \"étrangères\", \n",
    "        \"janet\", \"bibliothèque nationale\", \"blesenne\", \"lafloques\", \"setangue\", \"dorot\", \"lévêcque\", \"bade\", \"ginori\", \"itrie\", \n",
    "        \"cochinchine\", \"parme\", \n",
    "    ]\n",
    "    for elt in origin_blacklist:\n",
    "        if lib.has_element(origin, elt):\n",
    "            origin = lib.remove_element(origin, elt)\n",
    "\n",
    "\n",
    "    ##### Origins tweaks #####\n",
    "\n",
    "    if lib.has_element(origin, 'wedgwood'):\n",
    "        origin = lib.remove_element(origin, 'wedgwood')\n",
    "        origin = lib.add_element(origin, 'angleterre')\n",
    "        author = lib.add_element(author, 'wedgwood')\n",
    "    if lib.has_element(origin, 'minton'):\n",
    "        origin = lib.remove_element(origin, 'minton')\n",
    "        origin = lib.add_element(origin, 'angleterre')\n",
    "        author = lib.add_element(author, 'minton')\n",
    "    if lib.has_element(origin, 'savonnerie'):\n",
    "        origin = lib.remove_element(origin, 'savonnerie')\n",
    "        origin = lib.add_element(origin, 'angleterre')\n",
    "        author = lib.add_element(author, 'savonnerie')\n",
    "\n",
    "\n",
    "    ##### Periods tweaks #####\n",
    "\n",
    "    # For those who are on vi century, we observe that it is actually xvi, correct it if it is the case\n",
    "    if lib.has_element(period, 'vi') and 'seizième' in descr:\n",
    "        period = lib.remove_element(period, 'vi')\n",
    "        period = lib.add_element(period, 'xvi')\n",
    "\n",
    "    # \"siècle\" word is missing\n",
    "    add_siecle = ['vi', 'vii', 'viii', 'ix', 'x', 'xi', 'xii', 'xiii', 'xiv', 'xv', 'xvi', 'xvii', 'xviii', 'xix']\n",
    "    for to_add in add_siecle:\n",
    "        if lib.has_element(period, to_add):\n",
    "            period = lib.remove_element(period, to_add)\n",
    "            period = lib.add_element(period, to_add + 'e siècle')\n",
    "\n",
    "    # Those are not periods\n",
    "    period_blacklist = ['zièm', 'moindr', 'iii', 'xxii']\n",
    "    for bl in period_blacklist:\n",
    "        if lib.has_element(period, bl):\n",
    "            period = lib.remove_element(period, bl)\n",
    "\n",
    "\n",
    "    ##### Author tweaks #####\n",
    "\n",
    "    # Special case for Jean de Bologne\n",
    "    if \"d'après jean de bologne\" in descr or \"par jean de bologne\" in descr or \"de jean de bologne\" in descr or \"à jean de bologne\":\n",
    "        if lib.has_element(author, 'jean'): author = lib.remove_element(author, 'jean')\n",
    "        author = lib.add_element(author, \"jean de bologne\")\n",
    "\n",
    "    # Special case for Jean III Pénéaud\n",
    "    if \"jean iii péneaud\" in descr:\n",
    "        if lib.has_element(author, 'jean iii'): \n",
    "            author = lib.remove_element(author, 'jean iii')\n",
    "        author = lib.add_element(author, \"jean iii péneaud\")\n",
    "\n",
    "    # special case to remove from author and put as origin\n",
    "    not_authors_but_origins = [\"dresde\", \"genève\", \"naples\", \"carthage\", \"canton\", \"neuilly\", \"augsbourg\", \"ratisbonne\", \"leyde\", \"nuremberg\", \"saint-germain\", \"capo di monte\"]\n",
    "    for not_author in not_authors_but_origins:\n",
    "        if lib.has_element(author, not_author):\n",
    "            author = lib.remove_element(author, not_author)\n",
    "            origin = lib.add_element(origin, not_author)\n",
    "    \n",
    "\n",
    "\n",
    "    # Set the new values\n",
    "    objects.at[i, 'object_type'] = lib.clean_elements_str(obj_type) \n",
    "    objects.at[i, 'material_technique'] = lib.clean_elements_str(mat_tech)  \n",
    "    objects.at[i, 'origin'] = lib.clean_elements_str(origin) \n",
    "    objects.at[i, 'period'] = lib.clean_elements_str(period) \n",
    "    objects.at[i, 'author'] = lib.clean_elements_str(author) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all blacklisted authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(authors_blacklist_path, \"r\") as f:\n",
    "    blacklist = list(map(lambda s: s.strip().lower(), yaml.safe_load(f)))\n",
    "\n",
    "\n",
    "for i, row in objects.iterrows():\n",
    "\n",
    "    # Do nothing if there is no author\n",
    "    if pd.isna(row['author']): \n",
    "        continue\n",
    "\n",
    "    # Remove all blacklisted authors\n",
    "    authors = row['author']\n",
    "    for bl_auth in blacklist:\n",
    "        authors = lib.remove_element(authors, bl_auth)\n",
    "\n",
    "    # Reset in the table\n",
    "    objects.at[i, 'author'] = lib.clean_elements_str(authors) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
