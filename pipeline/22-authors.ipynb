{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9cb960e",
   "metadata": {},
   "source": [
    "Extract author information from lot descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb5887a",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0436cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, time\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import warnings\n",
    "import lib\n",
    "import yaml\n",
    "import ollama\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Paremeters from config file\n",
    "with open(\"./00-config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "catalog = config['catalog']['folder_name']\n",
    "spacy_model = config['catalog']['spacy_model']\n",
    "local_model = config['model']['local_model']\n",
    "cooldown = config['model']['local_cooldown']\n",
    "details = config['model']['author_details']\n",
    "\n",
    "# Overwrite variables in case of pipeline mode\n",
    "if os.getenv('OBJECTIVE_MODE') == 'pipeline':\n",
    "    catalog = os.getenv('OBJECTIVE_CATALOG')\n",
    "    \n",
    "# Global Variables\n",
    "nlp = spacy.load(spacy_model)\n",
    "nlp.add_pipe(\"merge_entities\")\n",
    "nlp.add_pipe(\"merge_noun_chunks\")\n",
    "eta = lib.Eta()\n",
    "folder_path = f\"../catalogs/{catalog}\"\n",
    "input_path = f'{folder_path}/objects.csv'\n",
    "output_path = f'{folder_path}/objects.csv'\n",
    "param_path = f\"./01-authors-blacklist.yaml\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03d17dc",
   "metadata": {},
   "source": [
    "### Load objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07766e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = pd.read_csv(input_path)\n",
    "objects['index'] = objects['index'].astype(pd.StringDtype())\n",
    "\n",
    "if 'author' not in objects.columns:\n",
    "    objects['author'] = pd.NA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eedeca",
   "metadata": {},
   "source": [
    "### Load authors blacklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0761b295",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(param_path, \"r\") as f:\n",
    "    blacklist = list(map(lambda s: s.strip().lower(), yaml.safe_load(f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1791308d",
   "metadata": {},
   "source": [
    "### Find authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda2a29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta.begin(len(objects), \"Finding authors\")\n",
    "for i, row in objects.iterrows():\n",
    "    authors = row['author'].lower() if pd.notna(row['author']) else \"\"\n",
    "\n",
    "    doc = nlp(row['description'])\n",
    "    word_before = \"\"\n",
    "    for token in doc:\n",
    "        if token.pos_ in ['PROPN', 'NOUN'] and word_before in [\"de\", \"par\", \"d'\"] and token.text[0].isupper():\n",
    "        \n",
    "            # Check if the token is blacklisted\n",
    "            if token.text.lower() in blacklist: \n",
    "                continue\n",
    "            \n",
    "            # If the option is set in the config file, display details for the authors part\n",
    "            if details:\n",
    "                # Reload blacklist, so that it can be extanded along the run\n",
    "                with open(param_path, \"r\") as f:\n",
    "                    blacklist = list(map(lambda s: s.strip().lower(), yaml.safe_load(f)))\n",
    "\n",
    "                # Print to increase blacklist\n",
    "                eta.print(\"Supposed author: \" + token.text)\n",
    "\n",
    "            # Ask LLM if it is the author\n",
    "            prompt = f\"From the following object description, can we say that {token.text} is the author?\\nHere is the description: \\\"{row['description']}\\\"\\nAnswer with a single word: \\\"yes\\\" or \\\"no\\\", with no additionnal explaination.\"\n",
    "            messages = [{ \"role\": \"user\", \"content\": prompt }]\n",
    "            response = ollama.chat(model=local_model, messages=messages)   \n",
    "            time.sleep(cooldown) # To let computer cool down\n",
    "            answer: str = response['message']['content']\n",
    "\n",
    "            # If LLM says yes, save result\n",
    "            if \"yes\" in answer.lower():\n",
    "                authors = lib.add_element(authors, token.text)\n",
    "\n",
    "        word_before = token.text\n",
    "\n",
    "    objects.at[i, 'author'] = lib.clean_elements_str(authors)\n",
    "\n",
    "    eta.iter()\n",
    "eta.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c116b8c3",
   "metadata": {},
   "source": [
    "### Save objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976ec014",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
