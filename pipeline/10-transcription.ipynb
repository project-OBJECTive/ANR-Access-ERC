{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcribe a catalogue using LLM capabilities: From PDF, to images, to texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "import base64\n",
    "import pymupdf\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from openai import OpenAI\n",
    "from mistralai import Mistral\n",
    "import ollama\n",
    "import lib\n",
    "import yaml\n",
    "\n",
    "# Paremeters from config file\n",
    "with open(\"./00-config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "catalog = config['catalog']['folder_name']\n",
    "catalog_language = config['catalog']['language']\n",
    "mode = config['model']['mode']\n",
    "llm_provider = config['model']['llm_provider']\n",
    "model = config['model']['vision_model']\n",
    "\n",
    "# Overwrite variables in case of pipeline mode\n",
    "if os.getenv('OBJECTIVE_MODE') == 'pipeline':\n",
    "    catalog = os.getenv('OBJECTIVE_CATALOG')\n",
    "\n",
    "# Global variables\n",
    "folder_path = f\"../catalogs/{catalog}\"\n",
    "eta = lib.Eta()\n",
    "if llm_provider == \"openai\": client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY_OBJECTIVE\"))\n",
    "if llm_provider == \"mistralai\": client = Mistral(api_key=os.getenv(\"MISTRALAI_API_KEY_OBJECTIVE\"))\n",
    "input_path = f\"{folder_path}/catalog.pdf\"\n",
    "output_path = f\"{folder_path}/transcription.txt\"\n",
    "page_begin = 0\n",
    "page_end = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt that will be sent to the LLM\n",
    "prompt = f\"\"\"\n",
    "Transcribe the following document, which is a scanned page of an auction book.\n",
    "Your answer can only contain the transcription: no comments, notes or explanation.\n",
    "If there is no text to transcribe, just answer \"[No text]\"\n",
    "If there is an image on the scan, integrate it in the transcription with a small description like \"[Image of a man walking on the road]\"\n",
    "If there are headers or footnotes, integrate them like: \"[footnote: Lorem ipsum]\", \"[header: Lorem ipsum]\"\n",
    "It is important that you ignore all handwritten notes. \n",
    "If there is a page number (top or bottom), integrate it like: \"[page number: 999]\"\n",
    "Keep the original transcription language ({catalog_language}).\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == \"direct\": \n",
    "    \n",
    "    doc = pymupdf.open(input_path)\n",
    "    eta.begin(doc.page_count, 'Transcribing catalogue')\n",
    "    for i, page in enumerate(doc[page_begin:page_end if page_end is not None else len(doc)]):\n",
    "\n",
    "        # Transform the pdf page into an image\n",
    "        pix = page.get_pixmap()\n",
    "        img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "        buffered = BytesIO()\n",
    "        img.save(buffered, format=\"JPEG\")\n",
    "        # img.save(f\"{folder_path}/page-{i}.jpg\", format=\"JPEG\") # Save the image on disk, for debugging\n",
    "        b64_image = base64.b64encode(buffered.getvalue()).decode()\n",
    "\n",
    "        # Ask OPEN AI\n",
    "        if llm_provider == \"openai\": \n",
    "            messages = [\n",
    "                { \"role\": \"user\", \"content\": [\n",
    "                    { \"type\": \"text\", \"text\": prompt },\n",
    "                    { \"type\": \"image_url\", \"image_url\": { \"url\": f\"data:image/jpeg;base64,{b64_image}\", \"detail\": \"high\" }}\n",
    "                ]}\n",
    "            ]\n",
    "            completion = client.chat.completions.create(model=model,messages=messages)\n",
    "            answer = completion.choices[0].message.content\n",
    "\n",
    "        # ASK MISTRAL\n",
    "        if llm_provider == \"mistralai\":\n",
    "            messages = [\n",
    "                { \"role\": \"user\", \"content\": [\n",
    "                    { \"type\": \"text\", \"text\": prompt },\n",
    "                    { \"type\": \"image_url\", \"image_url\": { \"url\": f\"data:image/jpeg;base64,{b64_image}\", \"detail\": \"high\" }}\n",
    "                ]}\n",
    "            ]\n",
    "            chat_response = client.chat.complete(model=model, messages=messages)\n",
    "            answer = chat_response.choices[0].message.content\n",
    "\n",
    "        # ASK OLLAMA\n",
    "        if llm_provider == \"ollama\":\n",
    "            messages = [{ \"role\": \"user\", \"content\": prompt, \"images\": [b64_image] }]\n",
    "            ollama_answer = ollama.chat(model=model, messages=messages)  \n",
    "            answer = ollama_answer['message']['content']\n",
    "\n",
    "        # For debugging:\n",
    "        # print(f'Page {i}, model answer:')\n",
    "        # print(answer)\n",
    "\n",
    "        # Append the current page transcription\n",
    "        transcription = f\"\\n\\n>>>>> [Page {i + 1}] >>>>>\\n\\n{answer}\"\n",
    "\n",
    "        # Save the transcription on disk\n",
    "        print('### Save transcription')\n",
    "        file = open(output_path, 'a')\n",
    "        file.write(transcription.replace('â€”', '-'))\n",
    "        file.close()\n",
    "\n",
    "        eta.iter()\n",
    "    eta.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH: Prepare tasks\n",
    "\n",
    "if mode == \"batch\":\n",
    "    batch_tasks = []\n",
    "\n",
    "    doc = pymupdf.open(input_path)\n",
    "    eta.begin(doc.page_count, 'Building batch tasks')\n",
    "    for i, page in enumerate(doc[page_begin:page_end if page_end is not None else len(doc)]):\n",
    "        \n",
    "        # Transform the pdf page into an image\n",
    "        pix = page.get_pixmap()\n",
    "        img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "        buffered = BytesIO()\n",
    "        img.save(buffered, format=\"JPEG\")\n",
    "        # img.save(f\"{folder_path}/page-{i}.jpg\", format=\"JPEG\") # Save the image on disk\n",
    "        b64_image = base64.b64encode(buffered.getvalue()).decode()\n",
    "        custom_id = f\"{catalog}-transcription-p{str(i).zfill(4)}\"\n",
    "\n",
    "\n",
    "        # Ask MISTRAL\n",
    "        if llm_provider == \"mistralai\":\n",
    "            messages = [\n",
    "                { \"role\": \"user\", \"content\": [\n",
    "                    { \"type\": \"text\", \"text\": prompt },\n",
    "                    { \"type\": \"image_url\", \"image_url\": { \"url\": f\"data:image/jpeg;base64,{b64_image}\", \"detail\": \"high\" }}\n",
    "                ]}\n",
    "            ]\n",
    "            batch_tasks.append({ \n",
    "                \"custom_id\": custom_id, \n",
    "                \"body\": { \"messages\": messages }\n",
    "            })\n",
    "\n",
    "        # Ask OPEN AI\n",
    "        if llm_provider == \"openai\": \n",
    "            messages = [\n",
    "                { \"role\": \"user\", \"content\": [\n",
    "                    { \"type\": \"text\", \"text\": prompt },\n",
    "                    { \"type\": \"image_url\", \"image_url\": { \"url\": f\"data:image/jpeg;base64,{b64_image}\", \"detail\": \"high\" }}\n",
    "                ]}\n",
    "            ]\n",
    "            batch_tasks.append({ \n",
    "                \"custom_id\": custom_id, \n",
    "                \"method\": \"POST\", \n",
    "                \"url\": \"/v1/chat/completions\", \n",
    "                \"body\": {\"model\": model, \"messages\": messages }\n",
    "            })\n",
    "\n",
    "\n",
    "        # ASK OLLAMA\n",
    "        if llm_provider == \"ollama\": \n",
    "            raise Exception('Batch not implemented with Ollama')\n",
    "\n",
    "        eta.iter()\n",
    "    eta.end()\n",
    "\n",
    "    print(f'{len(batch_tasks)} tasks created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH: Create the batch (and wait for results)\n",
    "\n",
    "if mode == \"batch\":\n",
    "    if llm_provider == \"mistralai\":\n",
    "        answers = lib.mistralai_batch_execution(\n",
    "            tasks=batch_tasks,\n",
    "            client=client, model=model, file_name=f\"batch-1-transcription-{catalog}\", task_name=f\"{catalog}_transcription\"\n",
    "        )\n",
    "    if llm_provider == \"openai\":\n",
    "        answers = lib.openai_batch_execution(\n",
    "            task=batch_tasks,\n",
    "            client=client, endpoint=\"/v1/chat/completions\", task_name=f\"{catalog}_transcription\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH: Build the transcription \n",
    "\n",
    "if mode == \"batch\":\n",
    "\n",
    "    transcription = \"\"\n",
    "    for i, answer in enumerate(answers):\n",
    "        page_index = i + 1\n",
    "        transcription += f\"\\n\\n>>>>> [PAGE {page_index}] >>>>>\\n\\n\"\n",
    "        transcription += answer.replace('\\n```', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH: Save the transcription\n",
    "\n",
    "if mode == \"batch\":\n",
    "\n",
    "    print('### Save transcription')\n",
    "    file = open(output_path, 'w')\n",
    "    file.write(transcription.replace('â€”', '-').replace('\\\\', '\\\\\\\\').replace('```', ''))\n",
    "    file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
