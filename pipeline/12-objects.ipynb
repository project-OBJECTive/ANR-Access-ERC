{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract information from lot descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "import json\n",
    "import pandas as pd\n",
    "import lib\n",
    "import ollama\n",
    "from mistralai import Mistral\n",
    "from openai import OpenAI\n",
    "import yaml\n",
    "\n",
    "# Paremeters from config file\n",
    "with open(\"./00-config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "catalog = config['catalog']['folder_name']\n",
    "catalog_language = config['catalog']['language']\n",
    "mode = config['model']['mode']\n",
    "llm_provider = config['model']['llm_provider']\n",
    "model = config['model']['language_model']\n",
    "object_number_by_prompt = config['model']['object_number_by_prompt']\n",
    "\n",
    "# Overwrite variables in case of pipeline mode\n",
    "if os.getenv('OBJECTIVE_MODE') == 'pipeline':\n",
    "    catalog = os.getenv('OBJECTIVE_CATALOG')\n",
    "\n",
    "# Global variables\n",
    "folder_path = f\"../catalogs/{catalog}\"\n",
    "eta = lib.Eta()\n",
    "if llm_provider == \"mistralai\": client = Mistral(api_key=os.getenv(\"MISTRALAI_API_KEY_OBJECTIVE\"))\n",
    "if llm_provider == \"openai\": client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY_OBJECTIVE\"))\n",
    "input_path = f'{folder_path}/list.txt'\n",
    "output_path = f'{folder_path}/objects.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "prompt = f\"\"\"\n",
    "From the following {object_number_by_prompt} descriptions of objects lots, extract me the following information. \n",
    "- description: the original description (with index)\n",
    "- index: the number given to the lot; eg \"1\", \"123\", \"45\"...\n",
    "- object_type: what the lot is; eg \"table\", \"plate\", \"statue\"...\n",
    "- number: how many object are in this lot; eg \"1\", \"2\", \"3\"...\n",
    "- material_technique (if mentioned): the main material of the lot with its technique if mentioned; eg \"painted enamel\", \"lacque\", \"embroidered silk\", \"carved wood\"...\n",
    "- origin (if mentioned): country or region of origin of the lot; eg \"Germany\", \"France\", \"Europe\"...\n",
    "Your answer should be a JSON object (an array of length {object_number_by_prompt}), do not add comments, notes or explanations.\n",
    "Each object property is a list and should be as small as possible, a few words at maximum.\n",
    "Extracted information should be in {catalog_language}.\n",
    "\n",
    "Here are the {object_number_by_prompt} descriptions:\n",
    "\"//descriptions//\"\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_value(value: str | int ) -> str:\n",
    "    \"\"\"Function to parse the return value of a description attribute.\"\"\"\n",
    "    if isinstance(value, list): return ', '.join(list(map(lambda v: str(v), value))).lower()\n",
    "    if isinstance(value, str): return value.lower()\n",
    "    if isinstance(value, int): return str(value)\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(input_path, 'r')\n",
    "objects = file.read().split('\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == \"direct\":\n",
    "    objects = []\n",
    "\n",
    "    eta.begin(len(objects), \"Extracting information from object description\")\n",
    "    for i in range(0, len(objects), object_number_by_prompt):\n",
    "        selection = objects[i:i+object_number_by_prompt]\n",
    "        descriptions = '\\n'.join(selection)\n",
    "\n",
    "        # Prompt creation\n",
    "        prompt_ = prompt.replace('//descriptions//', descriptions)\n",
    "        messages = [{'role': 'user', 'content': prompt_}]\n",
    "        \n",
    "        # Ask the LLM\n",
    "        if llm_provider == \"ollama\":\n",
    "            response = ollama.chat(model=model, messages=messages)\n",
    "            answer: str = response['message']['content']\n",
    "        if llm_provider == \"mistralai\":\n",
    "            response = client.chat.complete(model=model, messages=messages)\n",
    "            answer = response.choices[0].message.content\n",
    "        if llm_provider == \"openai\":\n",
    "            response = client.chat.completions.create(model=model, messages=messages)\n",
    "            answer = response.choices[0].message.content\n",
    "\n",
    "        # Parse the answer\n",
    "        try:\n",
    "            begin_index = answer.index('```json') + 7\n",
    "            end_index = answer.index('```', begin_index)\n",
    "            object = json.loads(answer[begin_index:end_index].strip())\n",
    "            record = {\n",
    "                \"description\": parse_value(object['description'] if 'description' in object else None),\n",
    "                \"index\": parse_value(object['index'] if 'index' in object else None),\n",
    "                \"object_type\": parse_value(object['object_type'] if 'object_type' in object else None),\n",
    "                \"material\": parse_value(object['material'] if 'material' in object else None),\n",
    "                \"origin\": parse_value(object['origin'] if 'origin' in object else None),\n",
    "                \"number\": parse_value(object['number'] if 'number' in object else None),\n",
    "            }\n",
    "            objects.append(record)\n",
    "\n",
    "        except Exception as err:\n",
    "            print('')\n",
    "            print(answer)\n",
    "            raise err\n",
    "\n",
    "        eta.iter(i)\n",
    "    eta.end()\n",
    "\n",
    "    print('### Save table')\n",
    "    objects = pd.DataFrame(data=objects)\n",
    "    objects.to_csv(output_path, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH: Prepare tasks\n",
    "\n",
    "if mode == \"batch\":\n",
    "    \n",
    "    batch_tasks = []\n",
    "\n",
    "    eta.begin(len(objects), \"Extracting information from object description\")\n",
    "    for i in range(0, len(objects), object_number_by_prompt):\n",
    "        selection = objects[i:i+object_number_by_prompt]\n",
    "        descriptions = '\\n'.join(selection)\n",
    "\n",
    "        # Prompt creation\n",
    "        prompt_ = prompt.replace('//descriptions//', descriptions)\n",
    "        messages = [{'role': 'user', 'content': prompt_}]\n",
    "        custom_id = f\"{catalog}-table-{str(i + 1).zfill(4)}\"\n",
    "\n",
    "        # Create an OpenAI task\n",
    "        if llm_provider == 'openai':\n",
    "            batch_tasks.append({\n",
    "                \"custom_id\": custom_id,\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/chat/completions\", \n",
    "                \"body\": {\"model\": model, \"messages\": messages }\n",
    "            })\n",
    "        \n",
    "        # Create a MistralAI task\n",
    "        if llm_provider == 'mistralai':\n",
    "            batch_tasks.append({ \n",
    "                \"custom_id\": custom_id, \n",
    "                \"body\": { \"messages\": messages }\n",
    "            })\n",
    "\n",
    "        # Create an Ollama task\n",
    "        if llm_provider == \"ollama\": \n",
    "            raise Exception('Batch not implemented with Ollama')\n",
    "\n",
    "        eta.iter(i)\n",
    "    eta.end()\n",
    "\n",
    "    print(f'{len(batch_tasks)} tasks created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH: Create the batch (and wait for results)\n",
    "\n",
    "if mode == \"batch\":\n",
    "    if llm_provider == \"mistralai\":\n",
    "        answers = lib.mistralai_batch_execution(\n",
    "            tasks=batch_tasks,\n",
    "            client=client, model=model, file_name=f\"batch-1-transcription-{catalog}\", task_name=f\"{catalog}_objects\",\n",
    "        )\n",
    "    if llm_provider == \"openai\":\n",
    "        answers = lib.openai_batch_execution(\n",
    "            task=batch_tasks,\n",
    "            client=client, endpoint=\"/v1/chat/completions\", task_name=f\"{catalog}_objects\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH: Parse answers and create output file\n",
    "\n",
    "if mode == 'batch':\n",
    "    \n",
    "    # Create the table\n",
    "    objects = []\n",
    "    objects_clue = [] # temp\n",
    "    for i, answer in enumerate(answers):\n",
    "        try:\n",
    "            # Extract the JSON from the answer\n",
    "            if \"```json\" in answer:\n",
    "                begin_index = answer.index('```json') + 7\n",
    "                end_index = answer.index('```', begin_index)\n",
    "                answer_obj_list = json.loads(answer[begin_index:end_index].strip())\n",
    "            elif \"```\" in answer:\n",
    "                begin_index = answer.index('```') + 3\n",
    "                end_index = answer.index('```', begin_index)\n",
    "                answer_obj_list = json.loads(answer[begin_index:end_index].strip())\n",
    "            else:\n",
    "                answer_obj_list = json.loads(answer)\n",
    "\n",
    "            objects_clue += answer_obj_list # temp\n",
    "\n",
    "\n",
    "            # Replace all arrays by a single value and add it to the table\n",
    "            for answer_obj in answer_obj_list:\n",
    "                for key, value in answer_obj.items():\n",
    "                    if isinstance(value, list):\n",
    "                        value_str = list(map(lambda v: str(v) if isinstance(v, int) else v, value))\n",
    "                        answer_obj[key] = ', '.join(value_str)\n",
    "                        if key != 'description': answer_obj[key] = answer_obj[key].lower()\n",
    "                if answer_obj['description'] and answer_obj['description'] != '':\n",
    "                    objects.append(answer_obj)\n",
    "                else: \n",
    "                    print('--- index', i)\n",
    "                    print(answer_obj)\n",
    "\n",
    "        except Exception as err:\n",
    "            print(answer)\n",
    "            print(answer_obj)\n",
    "            raise err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH: Save the table\n",
    "\n",
    "print('### Save result')\n",
    "if mode == \"batch\":\n",
    "    objects = pd.DataFrame(data=objects)\n",
    "    objects['index'] = objects['index'].astype(pd.StringDtype())\n",
    "    objects.to_csv(output_path, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In case there were a crash AFTER OUTPUT FILES HAS BEEN FETCHED this code finalizes the notebook from the output files\n",
    "# import json\n",
    "# import pandas as pd\n",
    "\n",
    "# catalog = \"1861-04-08_Prince-Soltykoff\"\n",
    "# folder_path = f\"../catalogs/{catalog}\"\n",
    "# output_path = f\"../batch_files/1861-04-08_Prince-Soltykoff_objects_output_2025-05-21_09-51.jsonl\"\n",
    "\n",
    "# # Read the output files\n",
    "# results = []\n",
    "# file = open(output_path, 'r')\n",
    "# for line in file.readlines():\n",
    "#     results.append(json.loads(line.strip()))\n",
    "# file.close()\n",
    "\n",
    "# # Sort results by given ids\n",
    "# results = sorted(results, key=lambda x: x['custom_id'])\n",
    "\n",
    "# # Get answers out of object\n",
    "# answers = []\n",
    "# for result in results:\n",
    "#     answer = result['response']['body']['choices'][0]['message']['content']\n",
    "#     answer = answer.replace('\\\\', '\\\\\\\\') # Because of an error\n",
    "#     answers.append(answer)\n",
    "\n",
    "\n",
    "# # Create the table\n",
    "# objects = []\n",
    "# objects_clue = [] # temp\n",
    "# for i, answer in enumerate(answers):\n",
    "#     try:\n",
    "#         # Extract the JSON from the answer\n",
    "#         if \"```json\" in answer:\n",
    "#             begin_index = answer.index('```json') + 7\n",
    "#             end_index = answer.index('```', begin_index)\n",
    "#             answer_obj_list = json.loads(answer[begin_index:end_index].strip())\n",
    "#         elif \"```\" in answer:\n",
    "#             begin_index = answer.index('```') + 3\n",
    "#             end_index = answer.index('```', begin_index)\n",
    "#             answer_obj_list = json.loads(answer[begin_index:end_index].strip())\n",
    "#         else:\n",
    "#             answer_obj_list = json.loads(answer)\n",
    "\n",
    "#         objects_clue += answer_obj_list # temp\n",
    "\n",
    "\n",
    "#         # Replace all arrays by a single value and add it to the table\n",
    "#         for answer_obj in answer_obj_list:\n",
    "#             for key, value in answer_obj.items():\n",
    "#                 if isinstance(value, list):\n",
    "#                     value_str = list(map(lambda v: str(v) if isinstance(v, int) else v, value))\n",
    "#                     answer_obj[key] = ', '.join(value_str)\n",
    "#                     if key != 'description': answer_obj[key] = answer_obj[key].lower()\n",
    "#             if answer_obj['description'] and answer_obj['description'] != '':\n",
    "#                 objects.append(answer_obj)\n",
    "#             else: \n",
    "#                 print('--- index', i)\n",
    "#                 print(answer_obj)\n",
    "\n",
    "#     except Exception as err:\n",
    "#         print(answer)\n",
    "#         print(answer_obj)\n",
    "#         raise err\n",
    "    \n",
    "# # Save the table\n",
    "# output_path = f'{folder_path}/objects.csv'\n",
    "# objects = pd.DataFrame(data=objects)\n",
    "# objects['index'] = objects['index'].astype(pd.StringDtype())\n",
    "# objects.to_csv(output_path, index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
