{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10d3e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "import warnings\n",
    "from collections import Counter\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b014c723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "\n",
    "# Read from disk\n",
    "objects = pd.read_csv('../data/objects-all.csv')\n",
    "vocabulary = pd.read_csv('../data/vocabulary-all.csv')\n",
    "catalogs = pd.read_csv('../data/catalogs.csv', sep=';')\n",
    "soltykoff = pd.read_csv('../data/sales-soltykoff.csv')\n",
    "\n",
    "# Extract geographical places\n",
    "geographical_places = vocabulary[vocabulary['type'] == 'origin']\n",
    "\n",
    "# Format correctly strings and extract the sale year\n",
    "objects['year'] = objects['catalog'].str.slice(0, 4).astype(pd.Int64Dtype())\n",
    "geographical_places['name'] = geographical_places['name'].str.title()\n",
    "objects['origin'] = objects['origin'].str.title()\n",
    "objects['author'] = objects['author'].str.title()\n",
    "\n",
    "# Change Period labels (caps)\n",
    "def caps_periods(raw_period):\n",
    "    if pd.isna(raw_period):\n",
    "        return pd.NA\n",
    "    arr = raw_period.split(', ')\n",
    "    to_return = []\n",
    "    for p in arr :\n",
    "        if \"e siècle\" in p: to_return.append(p.replace('e siècle', '').upper() + 'e siècle')\n",
    "        elif \"louis \" in p: to_return.append(\"Louis \" + p.replace('louis ', '').upper())\n",
    "        else: to_return.append(p.title())\n",
    "    return ', '.join(to_return)\n",
    "\n",
    "objects['period'] = [caps_periods(period) for period in objects['period']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf46b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSS for nbconvert \n",
    "\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    "    .jp-Cell { display: flex; justify-content: center; }     \n",
    "    .jp-Cell-outputWrapper { width: 65%; display: flex; justify-content: center; }    \n",
    "    .jp-Cell-inputWrapper { width: 65%; display: flex; justify-content: center; }     \n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a719813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch geographical places coordinates from Wikidata SPARQL endpoint\n",
    "\n",
    "wikidata_ids = geographical_places['identifier'].dropna().tolist()\n",
    "\n",
    "# SPARQL query with VALUES\n",
    "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "query = f\"\"\"\n",
    "    SELECT ?place ?lat ?lon\n",
    "    WHERE {{\n",
    "    VALUES ?place {{ {' '.join('wd:' + q for q in wikidata_ids)} }}\n",
    "    ?place p:P625 ?statement.\n",
    "    ?statement psv:P625 ?coords.\n",
    "    ?coords wikibase:geoLatitude ?lat;\n",
    "            wikibase:geoLongitude ?lon.\n",
    "    }}\n",
    "\"\"\"\n",
    "sparql.setQuery(query)\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "\n",
    "# Parse results into DataFrame\n",
    "rows = []\n",
    "for r in results[\"results\"][\"bindings\"]:\n",
    "    rows.append({\n",
    "        \"identifier\": r[\"place\"][\"value\"].split(\"/\")[-1],\n",
    "        \"lat\": float(r[\"lat\"][\"value\"]),\n",
    "        \"lon\": float(r[\"lon\"][\"value\"])\n",
    "    })\n",
    "\n",
    "# Add the fectch coordinates\n",
    "geographical_places = geographical_places.merge(pd.DataFrame(rows), on=\"identifier\", how=\"left\")\n",
    "\n",
    "# Remove duplicates\n",
    "geographical_places.drop_duplicates(subset=['name', 'identifier'], inplace=True)\n",
    "\n",
    "# geographical_places"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef499164",
   "metadata": {},
   "source": [
    "# Analysis 0: Cardinalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419c71f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of objects: {len(objects)}\")\n",
    "print()\n",
    "print()\n",
    "print('Attention, in following charts, records can have multiple origins, authors, period, and therefore can count multiple times.')\n",
    "print()\n",
    "\n",
    "## Origins ##\n",
    "\n",
    "all_origins = ', '.join(objects['origin'].dropna().tolist()).split(', ')\n",
    "origins_counts = pd.DataFrame.from_dict(Counter(all_origins), orient='index', columns=['count']).reset_index().sort_values('count', ascending=False)\n",
    "fig = px.bar(origins_counts, x='index', y='count', title=\"Origins counts\", labels={'index': 'Origin', 'count': 'Count'})\n",
    "fig.show()\n",
    "origin_unknown_nb = len(objects[pd.isna(objects['origin'])])\n",
    "origin_unknown_percent = round(100 * (origin_unknown_nb / len(objects)), 2)\n",
    "print(f\"Number of lots with unknown origin: {origin_unknown_nb} ({origin_unknown_percent} %)\")\n",
    "print()\n",
    "print()\n",
    "\n",
    "## Authors ## \n",
    "\n",
    "all_authors = ', '.join(objects['author'].dropna().tolist()).split(', ')\n",
    "all_authors = pd.DataFrame.from_dict(Counter(all_authors), orient='index', columns=['count']).reset_index().sort_values('count', ascending=False)\n",
    "fig = px.bar(all_authors, x='index', y='count', title=\"Authors counts\", labels={'index': 'Author', 'count': 'Count'})\n",
    "fig.show()\n",
    "author_unknown_nb = len(objects[pd.isna(objects['author'])])\n",
    "author_unknown_percent = round(100 * (author_unknown_nb / len(objects)), 2)\n",
    "print(f\"Number of lots with unknown author: {author_unknown_nb} ({author_unknown_percent} %)\")\n",
    "print()\n",
    "print()\n",
    "\n",
    "## Periods ## \n",
    "\n",
    "all_periods = ', '.join(objects['period'].dropna().tolist()).split(', ')\n",
    "all_periods = pd.DataFrame.from_dict(Counter(all_periods), orient='index', columns=['count']).reset_index().sort_values('count', ascending=False)\n",
    "fig = px.bar(all_periods, x='index', y='count', title=\"Periods counts\", labels={'index': 'Period', 'count': 'Count'})\n",
    "fig.show()\n",
    "period_unknown_nb = len(objects[pd.isna(objects['period'])])\n",
    "period_unknown_percent = round(100 * (period_unknown_nb / len(objects)), 2)\n",
    "print(f\"Number of lots with unknown period: {period_unknown_nb} ({period_unknown_percent} %)\")\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "## Unaligned vocabulary ##\n",
    "\n",
    "# Object types\n",
    "object_type_vocab = vocabulary[vocabulary['type'] == 'object_type']\n",
    "unaligned_object_types = object_type_vocab[pd.isna(object_type_vocab['identifier'])]\n",
    "unaligned_object_types_nb = len(unaligned_object_types)\n",
    "unaligned_object_types_percent = round(100 * (unaligned_object_types_nb / len(object_type_vocab)), 2)\n",
    "print(f'Total objects types number: {len(object_type_vocab)}')\n",
    "print(f'Number of unaligned objects types: {unaligned_object_types_nb} ({unaligned_object_types_percent} %)')\n",
    "print()\n",
    "\n",
    "# Materials and techniques\n",
    "mat_tech_vocab = vocabulary[vocabulary['type'] == 'material_technique']\n",
    "unaligned_mat_techs = mat_tech_vocab[pd.isna(mat_tech_vocab['identifier'])]\n",
    "unaligned_mat_techs_nb = len(unaligned_mat_techs)\n",
    "unaligned_mat_techs_percent = round(100 * (unaligned_mat_techs_nb / len(mat_tech_vocab)), 2)\n",
    "print(f'Total materials and/or technique number: {len(mat_tech_vocab)}')\n",
    "print(f'Number of unaligned materials and/or technique: {unaligned_mat_techs_nb} ({unaligned_mat_techs_percent} %)')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2410911e",
   "metadata": {},
   "source": [
    "# Analysis 1: Object origins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901530a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare origins\n",
    "\n",
    "# Get only objects (lots) with origins\n",
    "origins = objects[pd.notna(objects['origin'])]\n",
    "\n",
    "number = len(origins)\n",
    "percent = round(100 * (number / len(objects)), 2)\n",
    "print(f'Number of objects with known origin: {number} ({percent} %)')\n",
    "\n",
    "# Add the geocoordinates\n",
    "origins = origins.merge(geographical_places, left_on='origin', right_on='name', how='left')\n",
    "\n",
    "# Remove those without coordinates\n",
    "origins = origins[pd.notna(origins['lat'])].copy()\n",
    "\n",
    "# Create points labels\n",
    "origins['label'] = origins['object_type'].fillna('Unknown') + ' - ' + origins['material_technique'].fillna('Unknown')\n",
    "\n",
    "number = len(origins)\n",
    "percent = round(100 * (number / len(objects)), 2)\n",
    "print(f'Number of objects with known origin and known coordinates: {number} ({percent} %)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2768a3",
   "metadata": {},
   "source": [
    "### Map of all objects' origins across all catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc2b6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the map (all catalogs)\n",
    "\n",
    "map = folium.Map(location=[20,0], zoom_start=3, tiles=\"OpenStreetMap\")\n",
    "\n",
    "# Add marker cluster\n",
    "marker_cluster = MarkerCluster().add_to(map)\n",
    "\n",
    "# Add points to cluster\n",
    "for _, row in origins.iterrows():\n",
    "    label = str(row['label'])\n",
    "    folium.Marker(location=[row['lat'], row['lon']], tooltip=label, popup=label).add_to(marker_cluster)\n",
    "\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462bad10",
   "metadata": {},
   "source": [
    "### Map of all objects' origins for period 1839 to 1855"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5687cd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the map (1839 to 1855)\n",
    "\n",
    "map = folium.Map(location=[20,0], zoom_start=3, tiles=\"OpenStreetMap\")\n",
    "\n",
    "# Add marker cluster\n",
    "marker_cluster = MarkerCluster().add_to(map)\n",
    "\n",
    "# Add points to cluster\n",
    "origins_1839_1855 = origins[(origins['year'] >= 1839) & (origins['year'] <= 1855)]\n",
    "for _, row in origins_1839_1855.iterrows():\n",
    "    label = str(row['label'])\n",
    "    folium.Marker(location=[row['lat'], row['lon']], tooltip=label, popup=label).add_to(marker_cluster)\n",
    "\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52076883",
   "metadata": {},
   "source": [
    "### Map of all objects' origins for period 1861 to 1876"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4031ae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the map (1861 to 1876)\n",
    "\n",
    "map = folium.Map(location=[20,0], zoom_start=3, tiles=\"OpenStreetMap\")\n",
    "\n",
    "# Add marker cluster\n",
    "marker_cluster = MarkerCluster().add_to(map)\n",
    "\n",
    "# Add points to cluster\n",
    "origins_1861_1876 = origins[(origins['year'] >= 1861) & (origins['year'] <= 1876)]\n",
    "for _, row in origins_1861_1876.iterrows():\n",
    "    label = str(row['label'])\n",
    "    folium.Marker(location=[row['lat'], row['lon']], tooltip=label, popup=label).add_to(marker_cluster)\n",
    "\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df40d361",
   "metadata": {},
   "source": [
    "### Map of all objects' origins for period 1880 to 1895"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f265bc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the map (1880 to 1895)\n",
    "\n",
    "map = folium.Map(location=[20,0], zoom_start=3, tiles=\"OpenStreetMap\")\n",
    "\n",
    "# Add marker cluster\n",
    "marker_cluster = MarkerCluster().add_to(map)\n",
    "\n",
    "# Add points to cluster\n",
    "origins_1880_1895 = origins[(origins['year'] >= 1880) & (origins['year'] <= 1895)]\n",
    "for _, row in origins_1880_1895.iterrows():\n",
    "    label = str(row['label'])\n",
    "    folium.Marker(location=[row['lat'], row['lon']], tooltip=label, popup=label).add_to(marker_cluster)\n",
    "\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036572a0",
   "metadata": {},
   "source": [
    "# Analysis 2: Objects' origins and materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be46d93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare objects (lots) with origins and material and origins\n",
    "\n",
    "origins_materials = origins[pd.notna(origins['origin']) & pd.notna(origins['material_technique'])].copy().reset_index()\n",
    "\n",
    "number = len(origins_materials)\n",
    "percent = round(100 * (number / len(objects)), 2)\n",
    "print(f'Number of objects with known origin and materials: {number} ({percent} %)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f68ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract most commons materials and techniques to not overload chart\n",
    "\n",
    "top_nb = 40\n",
    "\n",
    "# Look for all unique mat and tech and count them\n",
    "all_materials_techniques = ', '.join(origins_materials['material_technique']).split(', ')\n",
    "counts = Counter(all_materials_techniques)\n",
    "\n",
    "top = counts.most_common(top_nb)\n",
    "top_strings = [item for item, _ in top]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57df20a8",
   "metadata": {},
   "source": [
    "### Map of most common objects' material/technique (top 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260d42de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create map\n",
    "map = folium.Map(location=[20, 0], zoom_start=3)\n",
    "\n",
    "# Add a layer for each material\n",
    "top_strings.sort()\n",
    "for mat in top_strings:\n",
    "    fg = folium.FeatureGroup(name=mat,show=True)\n",
    "    marker_cluster = MarkerCluster().add_to(fg)  \n",
    "    selection = origins_materials[origins_materials['material_technique'].str.contains(mat)]\n",
    "    for _, row in selection.iterrows():\n",
    "        folium.Marker([row['lat'], row['lon']], tooltip=row['label'], popup=row['label']).add_to(marker_cluster)\n",
    "    fg.add_to(map)\n",
    "\n",
    "# Add layer control (checkboxes)\n",
    "folium.LayerControl(collapsed=False).add_to(map)\n",
    "\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdbc22a",
   "metadata": {},
   "source": [
    "# Analyse 3: Object types variations across periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6e6035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare object types\n",
    "\n",
    "object_types = objects[pd.notna(objects['object_type'])]\n",
    "\n",
    "number = len(object_types)\n",
    "percent = round(100 * (number / len(objects)), 2)\n",
    "print(f'Number of objects with known object type: {number} ({percent} %)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dd9394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract most commons object type to not overload chart\n",
    "\n",
    "top_nb = 20\n",
    "\n",
    "# Get all unique object types and count them\n",
    "all_object_types = ', '.join(object_types['object_type']).split(', ')\n",
    "counts = Counter(all_object_types)\n",
    "\n",
    "# Get most common object types\n",
    "top = counts.most_common(top_nb)\n",
    "top_strings = [item for item, _ in top]\n",
    "top_strings.sort()\n",
    "\n",
    "# To filter lots: because one lot can have multiple mat and techniques (\"enamel, copper\")\n",
    "def is_in_top(object_type):\n",
    "    for t in top_strings: \n",
    "        if t in object_type: return True\n",
    "    return False\n",
    "selection = object_types[[is_in_top(row['object_type']) for __annotations__, row in object_types.iterrows()]]\n",
    "\n",
    "number = len(selection)\n",
    "percent = round(100 * (number / len(objects)), 2)\n",
    "print(f'Number of objects within the top {top_nb} object types: {number} ({percent} %)')\n",
    "\n",
    "\n",
    "# Prepare the 3 periods\n",
    "object_types_1839_1855 = Counter(', '.join(selection[(selection['year'] >= 1839) & (selection['year'] <= 1855)]['object_type'].tolist()).split(', '))\n",
    "object_types_1861_1876 = Counter(', '.join(selection[(selection['year'] >= 1861) & (selection['year'] <= 1876)]['object_type'].tolist()).split(', '))\n",
    "object_types_1880_1895 = Counter(', '.join(selection[(selection['year'] >= 1880) & (selection['year'] <= 1895)]['object_type'].tolist()).split(', '))\n",
    "\n",
    "combined = {k: [object_types_1839_1855.get(k, 0), object_types_1861_1876.get(k, 0), object_types_1880_1895.get(k, 0)] for k in top_strings}\n",
    "\n",
    "# Periods Labels\n",
    "x = ['1839 to 1855', '1861 to 1876', '1880 to 1895']\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add one chart for each object types\n",
    "for key, counts in combined.items():\n",
    "    fig.add_trace(go.Scatter(x=x, y=counts, mode='markers+lines', name=key))\n",
    "\n",
    "# Create the chart\n",
    "fig.update_layout(\n",
    "    title=f\"Evolution of object types ({top_nb} most common) presence in auctions across periods\",\n",
    "    xaxis_title=\"Periods\",\n",
    "    yaxis_title=\"Counts\",\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b9b4e2",
   "metadata": {},
   "source": [
    "# Analyse 4: Production periods variation across periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497fdd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare periods\n",
    "\n",
    "periods = objects[pd.notna(objects['period'])]\n",
    "\n",
    "number = len(periods)\n",
    "percent = round(100 * (number / len(objects)), 2)\n",
    "print(f'Number of objects with known production periods: {number} ({percent} %)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91248354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract most commons periods to not overload chart\n",
    "\n",
    "top_nb = 10\n",
    "\n",
    "# Get all unique periods and count them\n",
    "all_periods = ', '.join(periods['period']).split(', ')\n",
    "counts = Counter(all_periods)\n",
    "\n",
    "# Get most common periods\n",
    "top = counts.most_common(top_nb)\n",
    "top_strings = [item for item, _ in top]\n",
    "top_strings.sort()\n",
    "\n",
    "# To filter lots: because one lot can have multiple periods (\"louis xvi, renaissance\")\n",
    "def is_in_top(period):\n",
    "    for t in top_strings: \n",
    "        if t in period: return True\n",
    "    return False\n",
    "selection = periods[[is_in_top(row['period']) for __annotations__, row in periods.iterrows()]]\n",
    "\n",
    "number = len(selection)\n",
    "percent = round(100 * (number / len(objects)), 2)\n",
    "print(f'Number of objects within the top {top_nb} periods: {number} ({percent} %)')\n",
    "\n",
    "# Prepare the 3 periods\n",
    "periods_1839_1855 = Counter(', '.join(selection[(selection['year'] >= 1839) & (selection['year'] <= 1855)]['period'].tolist()).split(', '))\n",
    "periods_1861_1876 = Counter(', '.join(selection[(selection['year'] >= 1861) & (selection['year'] <= 1876)]['period'].tolist()).split(', '))\n",
    "periods_1880_1895 = Counter(', '.join(selection[(selection['year'] >= 1880) & (selection['year'] <= 1895)]['period'].tolist()).split(', '))\n",
    "\n",
    "combined = {k: [periods_1839_1855.get(k, 0), periods_1861_1876.get(k, 0), periods_1880_1895.get(k, 0)] for k in top_strings}\n",
    "\n",
    "# Periods Labels\n",
    "x = ['1839 to 1855', '1861 to 1876', '1880 to 1895']\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add one chart for each periods\n",
    "for key, counts in combined.items():\n",
    "    fig.add_trace(go.Scatter(x=x, y=counts, mode='markers+lines', name=key))\n",
    "\n",
    "# Create the chart\n",
    "fig.update_layout(\n",
    "    title=f\"Evolution of production periods ({top_nb} most common) presence in auctions across periods\",\n",
    "    xaxis_title=\"Periods\",\n",
    "    yaxis_title=\"Counts\",\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87e8e8b",
   "metadata": {},
   "source": [
    "# Analyse 5: Auctioneers and experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7478def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all auctioneers\n",
    "auctioneer = '\\n'.join(catalogs['auctioneer_names'].dropna().tolist()).split('\\n')\n",
    "auctioneer_counts = Counter(auctioneer)\n",
    "\n",
    "# Sort items by count descending\n",
    "sorted_items = auctioneer_counts.most_common()\n",
    "labels, counts = zip(*sorted_items)\n",
    "\n",
    "# Create a bar chart\n",
    "fig = go.Figure([go.Bar(x=labels, y=counts)])\n",
    "\n",
    "# Optional: add title and axis labels\n",
    "fig.update_layout(\n",
    "    title='Auctioneer participations in auction across all catalogues',\n",
    "    xaxis_title='Items',\n",
    "    yaxis_title='Count'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce61f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all expert names\n",
    "experts = '\\n'.join(catalogs['experts_names'].dropna().tolist()).split('\\n')\n",
    "experts = [x for x in experts if x != '']\n",
    "experts_counts = Counter(experts)\n",
    "\n",
    "# Sort items by count descending\n",
    "sorted_items = experts_counts.most_common()  # returns list of tuples (item, count)\n",
    "labels, counts = zip(*sorted_items)  # unzip into separate lists\n",
    "\n",
    "# Create a bar chart\n",
    "fig = go.Figure([go.Bar(x=labels, y=counts)])\n",
    "\n",
    "# Optional: add title and axis labels\n",
    "fig.update_layout(\n",
    "    title='Experts participations in auction across all catalogues',\n",
    "    xaxis_title='Items',\n",
    "    yaxis_title='Count'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee3b076",
   "metadata": {},
   "source": [
    "# Analyse 6: Soltykoff sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017c425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all \"id\" (idem) by the one above\n",
    "for i, row in soltykoff.iterrows():\n",
    "    if row['buyer'] == 'id': \n",
    "        soltykoff.at[i, 'buyer'] = soltykoff.iloc[i-1]['buyer']\n",
    "\n",
    "# Get the sum of all buyers\n",
    "buyers = soltykoff.groupby('buyer').sum().reset_index()[['buyer', 'price']].sort_values('price', ascending=False)\n",
    "\n",
    "# Calculate total and threshold\n",
    "total = buyers['price'].sum()\n",
    "threshold = 0.03  # In percent\n",
    "\n",
    "# Mark small buyers as 'Others'\n",
    "buyers['buyer'] = buyers.apply(lambda row: row['buyer'] if row['price']/total >= threshold else f'Others (lower than {threshold*100} %)', axis=1)\n",
    "\n",
    "# Re-aggregate after grouping small buyers\n",
    "buyers = buyers.groupby('buyer', as_index=False)['price'].sum()\n",
    "\n",
    "# Plot interactive pie chart\n",
    "fig = px.pie(buyers, names='buyer', values='price', title='Total Price by Buyer (in Francs)', color_discrete_sequence=px.colors.qualitative.Pastel)\n",
    "fig.update_traces(textinfo='label+value+percent')\n",
    "fig.update_layout(height=600, showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81d9a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get, thanks to the index the lots bought\n",
    "soltykoff_objects = objects[objects['catalog'] == '1861-04-08_Prince-Soltykoff']\n",
    "soltykoff_ = soltykoff.merge(soltykoff_objects[['index', 'object_type']], on='index', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429466d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=3, specs=[[{'type':'domain'}, {'type':'domain'}, {'type':'domain'}]], subplot_titles=[\"Seillère buyings\", \"Webb buyings\", \"Roussel buyings\"])\n",
    "\n",
    "## SEILLERE ##\n",
    "\n",
    "seillere = soltykoff_[soltykoff_['buyer'] == 'Seillère']\n",
    "total = seillere['price'].sum()\n",
    "threshold = 0.03  # 5% of total\n",
    "seillere['object_type'] = seillere.apply(lambda row: row['object_type'] if row['price']/total >= threshold else f'other (lower than {threshold * 100} %)', axis=1)\n",
    "seillere = seillere.groupby('object_type', as_index=False)['price'].sum().sort_values('price')\n",
    "seillere_pie = px.pie(seillere, names='object_type', values='price', title='Seillière buyings (in Franc)', color_discrete_sequence=px.colors.qualitative.Pastel)\n",
    "fig.add_trace(go.Pie(labels=seillere['object_type'], values=seillere['price'], name=\"Seillière buyings (in Franc)\", textinfo=\"label+value\"), 1, 1)\n",
    "\n",
    "## WEBB ##\n",
    "\n",
    "webb = soltykoff_[soltykoff_['buyer'] == 'Webb']\n",
    "total = webb['price'].sum()\n",
    "threshold = 0.03  # 5% of total\n",
    "webb['object_type'] = webb.apply(lambda row: row['object_type'] if row['price']/total >= threshold else f'other (lower than {threshold * 100} %)', axis=1)\n",
    "webb = webb.groupby('object_type', as_index=False)['price'].sum().sort_values('price')\n",
    "webb_pie = px.pie(webb, names='object_type', values='price', title='Seillière buyings (in Franc)', color_discrete_sequence=px.colors.qualitative.Pastel)\n",
    "fig.add_trace(go.Pie(labels=webb['object_type'], values=webb['price'], name=\"Seillière buyings (in Franc)\", textinfo=\"label+value\"), 1, 2)\n",
    "\n",
    "## ROUSSEL ##\n",
    "\n",
    "roussel = soltykoff_[soltykoff_['buyer'] == 'Roussel']\n",
    "total = roussel['price'].sum()\n",
    "threshold = 0.03  # 5% of total\n",
    "roussel['object_type'] = roussel.apply(lambda row: row['object_type'] if row['price']/total >= threshold else f'other (lower than {threshold * 100} %)', axis=1)\n",
    "roussel = roussel.groupby('object_type', as_index=False)['price'].sum().sort_values('price')\n",
    "roussel_pie = px.pie(roussel, names='object_type', values='price', title='Seillière buyings (in Franc)', color_discrete_sequence=px.colors.qualitative.Pastel)\n",
    "fig.add_trace(go.Pie(labels=roussel['object_type'], values=roussel['price'], name=\"Seillière buyings (in Franc)\", textinfo=\"label+value\"), 1, 3)\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    showlegend=False, \n",
    "    title=dict(text=\"Details about the 3 higher buyers of Soltykoff auction sale\", x=0.5, y=0.95)\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
